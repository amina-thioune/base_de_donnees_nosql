{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5bHCDw3UAEt"
   },
   "source": [
    "**Aminata THIOUNE**\n",
    "\n",
    "Groupe Augias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyTUPvlEg09f"
   },
   "source": [
    "**<h1>MongoDB</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOYlWD9Js2bf"
   },
   "source": [
    "**MongoDB** est une base de données NoSQL orientée document qui a gagné en popularité en raison de sa flexibilité et de sa capacité à gérer des données non structurées à grande échelle. Contrairement aux bases de données relationnelles qui utilisent des tables et des lignes, MongoDB stocke les données sous forme de documents BSON (Binary JSON), permettant ainsi une structure de données plus souple et évolutive. Cela signifie que chaque document peut avoir un schéma différent, offrant une grande liberté lors de la modélisation des données.\n",
    "\n",
    "L'un des principaux avantages de MongoDB est sa capacité à se scalabiliser horizontalement, ce qui permet de répartir les données sur plusieurs serveurs pour gérer des volumes de trafic importants. De plus, ses fonctionnalités intégrées, telles que l'indexation, la recherche textuelle et l'agrégation, facilitent l'accès et l'analyse des données. MongoDB est couramment utilisé dans des applications web modernes, des systèmes de gestion de contenu, et des plateformes d'e-commerce, où la rapidité et l'agilité dans la gestion des données sont essentielles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fO7ks7flg2jH"
   },
   "source": [
    "##**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pyob4UqsnIQf"
   },
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "22NZjr9onZgJ"
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFDtFOUUWz2o"
   },
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb+srv://username:password@mongodb.3esaj.mongodb.net/?retryWrites=true&w=majority&appName=MongoDB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6ZfInT4nueG",
    "outputId": "10ea027c-ff05-4403-b86b-ed6c3731277e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Créer une collection\n",
    "database = client[\"tp_mongodb\"]\n",
    "collection = database[\"test\"]\n",
    "\n",
    "document_list = {\"name\" : \"amina\", \"status\" : \"student\"}, {\"name\" : \"Dior\", \"status\" : \"student\" }\n",
    "\n",
    "# Pour insérer plusieurs documents dans la collection\n",
    "# on peut utliser insert_one pour ajouter uun seul document\n",
    "result = collection.insert_many(document_list)\n",
    "\n",
    "print(result.acknowledged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEqxcEo4VLR_",
    "outputId": "bafabe6c-05ab-4a71-ff04-ede2101c5819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afficher la liste des collections\n",
    "database.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Krwes9gtRuUj",
    "outputId": "90361f6d-b00f-4cb8-8863-df7411a28a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de documents dans la collection\n",
    "count = collection.count_documents({})\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJWyhDE3TRSF",
    "outputId": "37a7a5cd-cb92-4eec-d584-05592ed825b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('67366dcacddcbbed4846a164'), 'name': 'amina', 'status': 'student'}\n",
      "{'_id': ObjectId('67366dcacddcbbed4846a165'), 'name': 'Dior', 'status': 'student'}\n"
     ]
    }
   ],
   "source": [
    "# Affcher les documents de la collection\n",
    "# Utiliser find_one pour chercher un seul document de la collection\n",
    "find = collection.find()\n",
    "for document in find:\n",
    "  print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3w6En7nTiER",
    "outputId": "ad72bac6-3085-4a96-8fcf-75bab2def7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Retourne une estimation du nombre de documents dans la collection\n",
    "count_2 = collection.estimated_document_count()\n",
    "print(count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieNHMqRHTh5i",
    "outputId": "1c28d9bc-a62e-4311-d34e-b60d60b6c13d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dior\n",
      "amina\n"
     ]
    }
   ],
   "source": [
    "# Affiche toutes les valeurs distinctes du champ \"name\" dans la collection\n",
    "results_2 = collection.distinct(\"name\")\n",
    "for document in results_2:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1l9dmSkUokh",
    "outputId": "68ef180f-38f9-44b4-872e-863ec51df72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Modifier un champs dans la collection\n",
    "query_filter = { \"name\" : \"amina\" }\n",
    "update_operation = { \"$set\" :\n",
    "    { \"name\" : \"Amy\" }\n",
    "}\n",
    "result_3 = collection.update_one(query_filter, update_operation)\n",
    "print(result_3.modified_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eotqigvvUofz",
    "outputId": "769bb91a-9389-4958-f44d-81f54fd4de0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Insérer un document dans la collection\n",
    "result_4 =  collection.insert_one({\"name\" : \"Fatou\", \"status\" : \"student\"})\n",
    "print(result_4.acknowledged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJwcg21reJED",
    "outputId": "9993ddb2-e6e0-4ac9-cb03-124a12cda6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# remplace complètement un document dans la collection avec un nouveau document sans modifierl'identifiant\n",
    "query_filter = { \"Age\" : \"19\" }\n",
    "replace_document = {\"name\" :\"Dior\", \"Status\" : \"Student\", \"Age\" : \"19\" }\n",
    "result = collection.replace_one(query_filter, replace_document)\n",
    "print(result.modified_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DXyTlA3eJBf",
    "outputId": "529ff866-1606-4384-facd-2dd3e205e811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('67366dcacddcbbed4846a164'), 'name': 'Amy', 'status': 'student'}\n",
      "{'_id': ObjectId('67366dcacddcbbed4846a165'), 'name': 'Dior', 'status': 'student'}\n",
      "{'_id': ObjectId('67366dddcddcbbed4846a166'), 'name': 'Fatou', 'status': 'student'}\n"
     ]
    }
   ],
   "source": [
    "finds = collection.find()\n",
    "for document in finds:\n",
    "  print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIRxbHOqeI8D",
    "outputId": "d813aa68-bd6c-40ec-f8d5-4b173b6ef437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Supprimer un document\n",
    "query_filter = { \"name\" : \"Fatou\" }\n",
    "result = collection.delete_one(query_filter)\n",
    "print(result.deleted_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcEAp_wQeI6N",
    "outputId": "5e817740-f124-49ed-a11d-695ab346541e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('67366dcacddcbbed4846a164'), 'name': 'Amy', 'status': 'student'}\n",
      "{'_id': ObjectId('67366dcacddcbbed4846a165'), 'name': 'Dior', 'status': 'student'}\n"
     ]
    }
   ],
   "source": [
    "finds = collection.find()\n",
    "for document in finds:\n",
    "  print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2h_TYQ4VW-GN"
   },
   "outputs": [],
   "source": [
    "# Supprimer la base de données\n",
    "client.drop_database('tp_mongodb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ymGKU9e9wrW"
   },
   "source": [
    "##**Jointure sur des objets JSON**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVLOEACN94_t",
    "outputId": "1de07d4c-7a94-43b8-9904-14dccb55753d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test 2', 'Test 1', 'Prénom et nom']\n",
      "====================\n",
      "{'test': {'Hervé P': {'Test 2': '12.00 / 18', 'Test 1': '10.00 / 16'}, 'Laurent H': {'Test 2': '12.00 / 18', 'Test 1': '15.00 / 16'}, 'Destin L': {'Test 2': '7.00 / 18', 'Test 1': '11.00 / 16'}, 'Guillaume C': {'Test 2': '4.00 / 18', 'Test 1': '10.00 / 16'}, 'Haytem D': {'Test 2': '7.00 / 18', 'Test 1': '12.00 / 16'}, 'Cam Chau N': {'Test 2': '9.00 / 18', 'Test 1': '6.00 / 16'}, 'Sarra Z': {'Test 2': '6.00 / 18', 'Test 1': '11.00 / 16'}, 'Romulus L': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}, 'Thierno D': {'Test 2': '8.00 / 18', 'Test 1': '5.00 / 16'}, 'Rosenthal Preston R': {'Test 2': '13.00 / 18', 'Test 1': '13.00 / 16'}, 'Betty T': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}, 'Mouloud B': {'Test 2': '17.00 / 18', 'Test 1': '13.00 / 16'}, 'Joseph L': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}, 'Nataliya P': {'Test 2': '9.00 / 18', 'Test 1': '10.00 / 16'}}}\n",
      "====================\n",
      "{\"test\": {\"Herv\\u00e9 P\": {\"Test 2\": \"12.00 / 18\", \"Test 1\": \"10.00 / 16\"}, \"Laurent H\": {\"Test 2\": \"12.00 / 18\", \"Test 1\": \"15.00 / 16\"}, \"Destin L\": {\"Test 2\": \"7.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Guillaume C\": {\"Test 2\": \"4.00 / 18\", \"Test 1\": \"10.00 / 16\"}, \"Haytem D\": {\"Test 2\": \"7.00 / 18\", \"Test 1\": \"12.00 / 16\"}, \"Cam Chau N\": {\"Test 2\": \"9.00 / 18\", \"Test 1\": \"6.00 / 16\"}, \"Sarra Z\": {\"Test 2\": \"6.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Romulus L\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Thierno D\": {\"Test 2\": \"8.00 / 18\", \"Test 1\": \"5.00 / 16\"}, \"Rosenthal Preston R\": {\"Test 2\": \"13.00 / 18\", \"Test 1\": \"13.00 / 16\"}, \"Betty T\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Mouloud B\": {\"Test 2\": \"17.00 / 18\", \"Test 1\": \"13.00 / 16\"}, \"Joseph L\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Nataliya P\": {\"Test 2\": \"9.00 / 18\", \"Test 1\": \"10.00 / 16\"}}}\n",
      "<class 'str'>\n",
      "====================\n",
      "['Test 2', 'Test 1', 'Prénom et nom']\n",
      "====================\n",
      "{'test': {'Hervé P': {'Test 2': '12.00 / 18', 'Test 1': '10.00 / 16'}, 'Laurent H': {'Test 2': '12.00 / 18', 'Test 1': '15.00 / 16'}, 'Destin L': {'Test 2': '7.00 / 18', 'Test 1': '11.00 / 16'}, 'Guillaume C': {'Test 2': '4.00 / 18', 'Test 1': '10.00 / 16'}, 'Haytem D': {'Test 2': '7.00 / 18', 'Test 1': '12.00 / 16'}, 'Cam Chau N': {'Test 2': '9.00 / 18', 'Test 1': '6.00 / 16'}, 'Sarra Z': {'Test 2': '6.00 / 18', 'Test 1': '11.00 / 16'}, 'Romulus L': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}, 'Thierno D': {'Test 2': '8.00 / 18', 'Test 1': '5.00 / 16'}, 'Rosenthal Preston R': {'Test 2': '13.00 / 18', 'Test 1': '13.00 / 16'}, 'Betty T': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}, 'Mouloud B': {'Test 2': '17.00 / 18', 'Test 1': '13.00 / 16'}, 'Joseph L': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}, 'Nataliya P': {'Test 2': '9.00 / 18', 'Test 1': '10.00 / 16'}}}\n",
      "====================\n",
      "{\"test\": {\"Herv\\u00e9 P\": {\"Test 2\": \"12.00 / 18\", \"Test 1\": \"10.00 / 16\"}, \"Laurent H\": {\"Test 2\": \"12.00 / 18\", \"Test 1\": \"15.00 / 16\"}, \"Destin L\": {\"Test 2\": \"7.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Guillaume C\": {\"Test 2\": \"4.00 / 18\", \"Test 1\": \"10.00 / 16\"}, \"Haytem D\": {\"Test 2\": \"7.00 / 18\", \"Test 1\": \"12.00 / 16\"}, \"Cam Chau N\": {\"Test 2\": \"9.00 / 18\", \"Test 1\": \"6.00 / 16\"}, \"Sarra Z\": {\"Test 2\": \"6.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Romulus L\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Thierno D\": {\"Test 2\": \"8.00 / 18\", \"Test 1\": \"5.00 / 16\"}, \"Rosenthal Preston R\": {\"Test 2\": \"13.00 / 18\", \"Test 1\": \"13.00 / 16\"}, \"Betty T\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Mouloud B\": {\"Test 2\": \"17.00 / 18\", \"Test 1\": \"13.00 / 16\"}, \"Joseph L\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Nataliya P\": {\"Test 2\": \"9.00 / 18\", \"Test 1\": \"10.00 / 16\"}}}\n",
      "<class 'str'>\n",
      "====================\n",
      "{\"test\": {\"Herv\\u00e9 P\": {\"Test 2\": \"12.00 / 18\", \"Test 1\": \"10.00 / 16\"}, \"Laurent H\": {\"Test 2\": \"12.00 / 18\", \"Test 1\": \"15.00 / 16\"}, \"Destin L\": {\"Test 2\": \"7.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Guillaume C\": {\"Test 2\": \"4.00 / 18\", \"Test 1\": \"10.00 / 16\"}, \"Haytem D\": {\"Test 2\": \"7.00 / 18\", \"Test 1\": \"12.00 / 16\"}, \"Cam Chau N\": {\"Test 2\": \"9.00 / 18\", \"Test 1\": \"6.00 / 16\"}, \"Sarra Z\": {\"Test 2\": \"6.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Romulus L\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Thierno D\": {\"Test 2\": \"8.00 / 18\", \"Test 1\": \"5.00 / 16\"}, \"Rosenthal Preston R\": {\"Test 2\": \"13.00 / 18\", \"Test 1\": \"13.00 / 16\"}, \"Betty T\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Mouloud B\": {\"Test 2\": \"17.00 / 18\", \"Test 1\": \"13.00 / 16\"}, \"Joseph L\": {\"Test 2\": \"11.00 / 18\", \"Test 1\": \"11.00 / 16\"}, \"Nataliya P\": {\"Test 2\": \"9.00 / 18\", \"Test 1\": \"10.00 / 16\"}}}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def csv_to_json_first_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    my_dict = {}\n",
    "    with open(csv_file, encoding = 'latin1') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile)\n",
    "        print(my_reader.fieldnames)\n",
    "        my_data = [my_row for my_row in my_reader]\n",
    "        for my_row in my_data:\n",
    "            #print(my_row)\n",
    "            my_dict = {}\n",
    "            my_dict[my_reader.fieldnames[0]] = my_row[my_reader.fieldnames[0]]\n",
    "            my_dict[my_reader.fieldnames[1]] = my_row[my_reader.fieldnames[1]]\n",
    "            data_dict[my_row[my_reader.fieldnames[2]]] = my_dict\n",
    "    print(\"====================\")\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = data_dict\n",
    "    print(my_my_dict)\n",
    "    #for item in data_dict.items():\n",
    "    #    print(item)\n",
    "    #\n",
    "    # convert both intermediary results to JSON object\n",
    "    #\n",
    "    y = dumps(my_my_dict)\n",
    "    print(\"====================\")\n",
    "    print(y)\n",
    "    print(type(y))\n",
    "    print(\"====================\")\n",
    "\n",
    "    return y\n",
    "\n",
    "def csv_to_json_second_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    csv_rows = []\n",
    "    #open a csv file handlerh\n",
    "    with open(csv_file, encoding = 'latin1', newline='') as csv_file_handler:\n",
    "        csv_reader = csv.DictReader(csv_file_handler)\n",
    "        field = csv_reader.fieldnames\n",
    "        for row in csv_reader:\n",
    "            #print([{field[i]:row[field[i]] for i in range(len(field))}])\n",
    "            csv_rows.extend([{field[i]:row[field[i]] for i in range(len(field))}])\n",
    "\n",
    "    print(\"====================\")\n",
    "    data_dict['test'] = csv_rows\n",
    "    #print(type(csv_rows))\n",
    "    print(data_dict)\n",
    "    #print(data_dict['test'][0])\n",
    "    #print(\"====================\")\n",
    "\n",
    "    #\n",
    "    # convert intermediary results to JSON object\n",
    "    #\n",
    "    z = dumps(data_dict)\n",
    "    print(\"====================\")\n",
    "    print(z)\n",
    "    print(type(z))\n",
    "    print(\"====================\")\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "def jointure(json1, json2):\n",
    "\n",
    "    from json import loads\n",
    "    from json import dumps\n",
    "\n",
    "    # First, transform json objects to dictionaries\n",
    "\n",
    "    d1_name = list(loads(json1))[0]\n",
    "    #print(d1_name)\n",
    "    d2_name = list(loads(json2))[0]\n",
    "    #print(d2_name)\n",
    "\n",
    "    d1 = loads(json1)[d1_name]\n",
    "    d2 = loads(json2)[d2_name]\n",
    "\n",
    "    #print(att_name,type(att_name))\n",
    "    # Second, iterate through dictionaries\n",
    "    d_res = {}\n",
    "    for key1, val1 in d1.items():\n",
    "        #print(key1, '==', val1)\n",
    "        for key2, val2 in d2.items():\n",
    "            #print(key1, '==', key2)\n",
    "            #print([ord(c) for c in key1],key1,[ord(c) for c in att_name],att_name)\n",
    "            if key1 == key2:\n",
    "                d = {}\n",
    "                d.update(val1)\n",
    "                d.update(val2)\n",
    "                #print(d)\n",
    "                d_res[key1] = d\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = d_res\n",
    "    z = dumps(my_my_dict)\n",
    "\n",
    "    return z\n",
    "\n",
    "# Main program\n",
    "\n",
    "json_one = csv_to_json_first_method(\"../data/test.csv\")\n",
    "json_two = csv_to_json_first_method(\"../data/test_1.csv\")\n",
    "\n",
    "d = jointure (json_one, json_two)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0JtwA_Xg6pZ"
   },
   "source": [
    "##**JSON/MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UuVYrKzXjt1s"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def json_to_mongodb(json_file):\n",
    "    # Charger le contenu du fichier JSON\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Récupérer les éléments sous 'test', qui est un dictionnaire de dictionnaires\n",
    "    items = data.get('test', {})\n",
    "\n",
    "    # Créer une collection de mongodb\n",
    "    collection = database[\"exo_mongo\"]\n",
    "\n",
    "    # Vérifier que 'items' est bien un dictionnaire\n",
    "    if isinstance(items, dict):\n",
    "        # Créer une liste de documents où chaque document inclut le nom\n",
    "        documents = [{'name': name, 'notes': scores} for name, scores in items.items()]\n",
    "\n",
    "        # Insérer les documents dans MongoDB\n",
    "        collection.insert_many(documents)\n",
    "    else:\n",
    "        return \"Le contenu sous 'test' n'est pas un dictionnaire.\"\n",
    "\n",
    "    return collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YtGjtIkuw9of"
   },
   "outputs": [],
   "source": [
    "# Fonction pour sauvegarder des données JSON dans un fichier\n",
    "def save_json_to_file(json_data, json_file):\n",
    "    with open(json_file, 'w') as f:\n",
    "        # Si `json_data` est une chaîne, la convertir en dictionnaire\n",
    "        if isinstance(json_data, str):\n",
    "            try:\n",
    "                json_data = json.loads(json_data)\n",
    "            except (TypeError, json.JSONDecodeError):\n",
    "                pass\n",
    "        json.dump(json_data, f, indent=4)\n",
    "\n",
    "\n",
    "json_file = 'data.json'\n",
    "\n",
    "save_json_to_file(json_one, json_file)\n",
    "\n",
    "collection_2 = json_to_mongodb(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gj4FKxwJyKBJ",
    "outputId": "c2085781-bc05-4b2d-f7f4-733fa62c39e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('67366e1ecddcbbed4846a167'), 'name': 'Hervé P', 'notes': {'Test 2': '12.00 / 18', 'Test 1': '10.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a168'), 'name': 'Laurent H', 'notes': {'Test 2': '12.00 / 18', 'Test 1': '15.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a169'), 'name': 'Destin L', 'notes': {'Test 2': '7.00 / 18', 'Test 1': '11.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a16a'), 'name': 'Guillaume C', 'notes': {'Test 2': '4.00 / 18', 'Test 1': '10.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a16b'), 'name': 'Haytem D', 'notes': {'Test 2': '7.00 / 18', 'Test 1': '12.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a16c'), 'name': 'Cam Chau N', 'notes': {'Test 2': '9.00 / 18', 'Test 1': '6.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a16d'), 'name': 'Sarra Z', 'notes': {'Test 2': '6.00 / 18', 'Test 1': '11.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a16e'), 'name': 'Romulus L', 'notes': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a16f'), 'name': 'Thierno D', 'notes': {'Test 2': '8.00 / 18', 'Test 1': '5.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a170'), 'name': 'Rosenthal Preston R', 'notes': {'Test 2': '13.00 / 18', 'Test 1': '13.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a171'), 'name': 'Betty T', 'notes': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a172'), 'name': 'Mouloud B', 'notes': {'Test 2': '17.00 / 18', 'Test 1': '13.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a173'), 'name': 'Joseph L', 'notes': {'Test 2': '11.00 / 18', 'Test 1': '11.00 / 16'}}\n",
      "{'_id': ObjectId('67366e1ecddcbbed4846a174'), 'name': 'Nataliya P', 'notes': {'Test 2': '9.00 / 18', 'Test 1': '10.00 / 16'}}\n"
     ]
    }
   ],
   "source": [
    "# Afficher la collection\n",
    "result = collection_2.find()\n",
    "for document in result:\n",
    "  print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6A3U1zzdzMe8",
    "outputId": "43fc0a19-f59b-4a66-9cde-f29063e758a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nIndexesWas': 1,\n",
       " 'ns': 'tp_mongodb.exo_mongo',\n",
       " 'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1731620390, 4),\n",
       "  'signature': {'hash': b'\\x12\\xc1Z\\xb4\\xce\\xe3\\xd78D\\x0e\\xd5?\\x11\\xd5-\\xb7:\\xd7\\xe6r',\n",
       "   'keyId': 7374129255736672259}},\n",
       " 'operationTime': Timestamp(1731620390, 4)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supprimer la collection\n",
    "database.drop_collection(\"exo_mongo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXTVpSR0Yr9K"
   },
   "source": [
    "##**Jointure de représentations JSON et interactions avec MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wz_8Da24YvDO",
    "outputId": "0d9b92a7-9608-446d-fb82-75c49799a36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pymongo.synchronous.collection.Collection'> 67366e34cddcbbed4846a175 67366e34cddcbbed4846a176\n",
      "{'Betty T': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Cam Chau N': {'Test 1': '6.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Destin L': {'Test 1': '11.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Guillaume C': {'Test 1': '10.00 / 16', 'Test 2': '4.00 / 18'},\n",
      " 'Haytem D': {'Test 1': '12.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Hervé P': {'Test 1': '10.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Joseph L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Laurent H': {'Test 1': '15.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Mouloud B': {'Test 1': '13.00 / 16', 'Test 2': '17.00 / 18'},\n",
      " 'Nataliya P': {'Test 1': '10.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Romulus L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Rosenthal Preston R': {'Test 1': '13.00 / 16', 'Test 2': '13.00 / 18'},\n",
      " 'Sarra Z': {'Test 1': '11.00 / 16', 'Test 2': '6.00 / 18'},\n",
      " 'Thierno D': {'Test 1': '5.00 / 16', 'Test 2': '8.00 / 18'},\n",
      " '_id': ObjectId('67366e34cddcbbed4846a175')}\n",
      "{'Betty T': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Cam Chau N': {'Test 1': '6.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Destin L': {'Test 1': '11.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Guillaume C': {'Test 1': '10.00 / 16', 'Test 2': '4.00 / 18'},\n",
      " 'Haytem D': {'Test 1': '12.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Hervé P': {'Test 1': '10.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Joseph L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Laurent H': {'Test 1': '15.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Mouloud B': {'Test 1': '13.00 / 16', 'Test 2': '17.00 / 18'},\n",
      " 'Nataliya P': {'Test 1': '10.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Romulus L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Rosenthal Preston R': {'Test 1': '13.00 / 16', 'Test 2': '13.00 / 18'},\n",
      " 'Sarra Z': {'Test 1': '11.00 / 16', 'Test 2': '6.00 / 18'},\n",
      " 'Thierno D': {'Test 1': '5.00 / 16', 'Test 2': '8.00 / 18'},\n",
      " '_id': ObjectId('67366e34cddcbbed4846a176')}\n",
      "{'_id': ObjectId('67366e34cddcbbed4846a177'),\n",
      " 'test': {'Betty T': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      "          'Cam Chau N': {'Test 1': '6.00 / 16', 'Test 2': '9.00 / 18'},\n",
      "          'Destin L': {'Test 1': '11.00 / 16', 'Test 2': '7.00 / 18'},\n",
      "          'Guillaume C': {'Test 1': '10.00 / 16', 'Test 2': '4.00 / 18'},\n",
      "          'Haytem D': {'Test 1': '12.00 / 16', 'Test 2': '7.00 / 18'},\n",
      "          'Hervé P': {'Test 1': '10.00 / 16', 'Test 2': '12.00 / 18'},\n",
      "          'Joseph L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      "          'Laurent H': {'Test 1': '15.00 / 16', 'Test 2': '12.00 / 18'},\n",
      "          'Mouloud B': {'Test 1': '13.00 / 16', 'Test 2': '17.00 / 18'},\n",
      "          'Nataliya P': {'Test 1': '10.00 / 16', 'Test 2': '9.00 / 18'},\n",
      "          'Romulus L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      "          'Rosenthal Preston R': {'Test 1': '13.00 / 16',\n",
      "                                  'Test 2': '13.00 / 18'},\n",
      "          'Sarra Z': {'Test 1': '11.00 / 16', 'Test 2': '6.00 / 18'},\n",
      "          'Thierno D': {'Test 1': '5.00 / 16', 'Test 2': '8.00 / 18'}}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  1. Conversion CSV en JSON : Le code lit un fichier CSV, extrait les données des trois premières colonnes, et les organise dans un dictionnaire structuré, avant de le convertir en JSON.\n",
    "  2. Jointure MongoDB : Il récupère deux documents à partir de MongoDB via leurs identifiants, puis effectue une jointure en fusionnant les clés communes des deux documents, en excluant les champs `_id`.\n",
    "  3. Programme principal : Le programme insère deux fichiers CSV convertis en JSON dans MongoDB, effectue une jointure sur ces documents, puis affiche et nettoie la base de données.\n",
    "\"\"\"\n",
    "\n",
    "def csv_to_json_first_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    my_dict = {}\n",
    "    with open(csv_file, encoding = 'latin1') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile)\n",
    "        #print(my_reader.fieldnames)\n",
    "        my_data = [my_row for my_row in my_reader]\n",
    "        for my_row in my_data:\n",
    "            #print(my_row)\n",
    "            my_dict = {}\n",
    "            my_dict[my_reader.fieldnames[0]] = my_row[my_reader.fieldnames[0]]\n",
    "            my_dict[my_reader.fieldnames[1]] = my_row[my_reader.fieldnames[1]]\n",
    "            data_dict[my_row[my_reader.fieldnames[2]]] = my_dict\n",
    "    #print(\"====================\")\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = data_dict\n",
    "  \n",
    "    # convert both intermediary results to JSON object\n",
    "    y = dumps(my_my_dict)\n",
    "  \n",
    "   \n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def jointure(mc,id1,id2):\n",
    "\n",
    "    print(type(mc),id1,id2)\n",
    "    doc1 = mc.find({'_id':id1})\n",
    "    doc2 = mc.find({'_id':id2})\n",
    "\n",
    "    # Second, iterate through dictionaries\n",
    "    d_res = {}\n",
    "    for d1 in doc1:\n",
    "        d11 = list(d1.keys())\n",
    "        res1 = d1\n",
    "        #print('==',d11,'==')\n",
    "    for d2 in doc2:\n",
    "        d22 = list(d2.keys())\n",
    "        res2 = d2\n",
    "        #print('==',d22,'==')\n",
    "    for d_111 in d11:\n",
    "       for d_222 in d22:\n",
    "           if d_111 != '_id' and d_222 != '_id':\n",
    "               if d_111 == d_222:\n",
    "                   d = {}\n",
    "                   d.update(res1[d_111])\n",
    "                   d.update(res2[d_222])\n",
    "                   #print(d)\n",
    "                   d_res[d_111] = d\n",
    "                   #print(\"**\",d_111,d_222,\"**\")\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = d_res\n",
    "    z = dumps(my_my_dict)\n",
    "\n",
    "    # Save the join in the collection\n",
    "    mc.insert_one(my_my_dict)\n",
    "\n",
    "    return z\n",
    "\n",
    "# Main program\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    mydb = client[\"mydatabase\"]\n",
    "    mycol = mydb[\"mycollection\"]\n",
    "\n",
    "\n",
    "    from json import loads\n",
    "    from json import dumps\n",
    "\n",
    "    # First, transform json objects to dictionaries\n",
    "\n",
    "    d1_name = list(loads(json_one))[0]\n",
    "    #print(d1_name)\n",
    "    d2_name = list(loads(json_two))[0]\n",
    "    #print(d2_name)\n",
    "\n",
    "    d1 = loads(json_one)[d1_name]\n",
    "    d2 = loads(json_two)[d2_name]\n",
    "\n",
    "    # store them into MongoDB\n",
    "\n",
    "    #client.test_database.drop()\n",
    "    post_id_one = mycol.insert_one(d1).inserted_id\n",
    "    post_id_two = mycol.insert_one(d2).inserted_id\n",
    "\n",
    "    # compute the join\n",
    "\n",
    "    d = jointure (mycol,post_id_one,post_id_two)\n",
    "    #print(d)\n",
    "\n",
    "    # print the 3 documents in the collection\n",
    "    from pprint import pprint\n",
    "\n",
    "    cursor = mycol.find({})\n",
    "    for document in cursor:\n",
    "        pprint(document)\n",
    "\n",
    "    # On fait du mÃ©nage\n",
    "    mycol.drop()\n",
    "    client.drop_database('mydatabase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOlD_O8xcYZ3"
   },
   "source": [
    "##**Intersections de représentations JSON et interactions avec MongoDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84LExFLMcfci",
    "outputId": "aef9bb79-6a55-4912-fca4-f72f6b07e47e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Betty T': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Cam Chau N': {'Test 1': '6.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Destin L': {'Test 1': '11.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Guillaume C': {'Test 1': '10.00 / 16', 'Test 2': '4.00 / 18'},\n",
      " 'Haytem D': {'Test 1': '12.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Hervé P': {'Test 1': '10.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Joseph L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Laurent H': {'Test 1': '15.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Mouloud B': {'Test 1': '13.00 / 16', 'Test 2': '17.00 / 18'},\n",
      " 'Nataliya P': {'Test 1': '10.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Romulus L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Rosenthal Preston R': {'Test 1': '13.00 / 16', 'Test 2': '13.00 / 18'},\n",
      " 'Sarra Z': {'Test 1': '11.00 / 16', 'Test 2': '6.00 / 18'},\n",
      " 'Thierno D': {'Test 1': '5.00 / 16', 'Test 2': '8.00 / 18'},\n",
      " '_id': ObjectId('67366e43cddcbbed4846a178')}\n",
      "{'Betty T': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Cam Chau N': {'Test 1': '6.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Destin L': {'Test 1': '11.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Guillaume C': {'Test 1': '10.00 / 16', 'Test 2': '4.00 / 18'},\n",
      " 'Haytem D': {'Test 1': '12.00 / 16', 'Test 2': '7.00 / 18'},\n",
      " 'Hervé P': {'Test 1': '10.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Joseph L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Laurent H': {'Test 1': '15.00 / 16', 'Test 2': '12.00 / 18'},\n",
      " 'Mouloud B': {'Test 1': '13.00 / 16', 'Test 2': '17.00 / 18'},\n",
      " 'Nataliya P': {'Test 1': '10.00 / 16', 'Test 2': '9.00 / 18'},\n",
      " 'Romulus L': {'Test 1': '11.00 / 16', 'Test 2': '11.00 / 18'},\n",
      " 'Rosenthal Preston R': {'Test 1': '13.00 / 16', 'Test 2': '13.00 / 18'},\n",
      " 'Sarra Z': {'Test 1': '11.00 / 16', 'Test 2': '6.00 / 18'},\n",
      " 'Thierno D': {'Test 1': '5.00 / 16', 'Test 2': '8.00 / 18'},\n",
      " '_id': ObjectId('67366e43cddcbbed4846a179')}\n",
      "{'_id': ObjectId('67366e43cddcbbed4846a17a'),\n",
      " 'test': {'Betty T': {'Test 1': '[\"11.00 / 16\", \"11.00 / 16\"]',\n",
      "                      'Test 2': '[\"11.00 / 18\", \"11.00 / 18\"]'},\n",
      "          'Cam Chau N': {'Test 1': '[\"6.00 / 16\", \"6.00 / 16\"]',\n",
      "                         'Test 2': '[\"9.00 / 18\", \"9.00 / 18\"]'},\n",
      "          'Destin L': {'Test 1': '[\"11.00 / 16\", \"11.00 / 16\"]',\n",
      "                       'Test 2': '[\"7.00 / 18\", \"7.00 / 18\"]'},\n",
      "          'Guillaume C': {'Test 1': '[\"10.00 / 16\", \"10.00 / 16\"]',\n",
      "                          'Test 2': '[\"4.00 / 18\", \"4.00 / 18\"]'},\n",
      "          'Haytem D': {'Test 1': '[\"12.00 / 16\", \"12.00 / 16\"]',\n",
      "                       'Test 2': '[\"7.00 / 18\", \"7.00 / 18\"]'},\n",
      "          'Hervé P': {'Test 1': '[\"10.00 / 16\", \"10.00 / 16\"]',\n",
      "                      'Test 2': '[\"12.00 / 18\", \"12.00 / 18\"]'},\n",
      "          'Joseph L': {'Test 1': '[\"11.00 / 16\", \"11.00 / 16\"]',\n",
      "                       'Test 2': '[\"11.00 / 18\", \"11.00 / 18\"]'},\n",
      "          'Laurent H': {'Test 1': '[\"15.00 / 16\", \"15.00 / 16\"]',\n",
      "                        'Test 2': '[\"12.00 / 18\", \"12.00 / 18\"]'},\n",
      "          'Mouloud B': {'Test 1': '[\"13.00 / 16\", \"13.00 / 16\"]',\n",
      "                        'Test 2': '[\"17.00 / 18\", \"17.00 / 18\"]'},\n",
      "          'Nataliya P': {'Test 1': '[\"10.00 / 16\", \"10.00 / 16\"]',\n",
      "                         'Test 2': '[\"9.00 / 18\", \"9.00 / 18\"]'},\n",
      "          'Romulus L': {'Test 1': '[\"11.00 / 16\", \"11.00 / 16\"]',\n",
      "                        'Test 2': '[\"11.00 / 18\", \"11.00 / 18\"]'},\n",
      "          'Rosenthal Preston R': {'Test 1': '[\"13.00 / 16\", \"13.00 / 16\"]',\n",
      "                                  'Test 2': '[\"13.00 / 18\", \"13.00 / 18\"]'},\n",
      "          'Sarra Z': {'Test 1': '[\"11.00 / 16\", \"11.00 / 16\"]',\n",
      "                      'Test 2': '[\"6.00 / 18\", \"6.00 / 18\"]'},\n",
      "          'Thierno D': {'Test 1': '[\"5.00 / 16\", \"5.00 / 16\"]',\n",
      "                        'Test 2': '[\"8.00 / 18\", \"8.00 / 18\"]'}}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  1. Conversion CSV en JSON : Le code lit un fichier CSV, extrait les données, les organise dans un dictionnaire structuré, puis les convertit en JSON.\n",
    "  2. Intersection MongoDB : Il calcule l'intersection des clés communes entre deux documents MongoDB et fusionne leurs valeurs.\n",
    "  3. Programme principal : Le programme insère deux fichiers CSV convertis en JSON dans MongoDB, effectue une intersection des documents, puis affiche et supprime les données.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def csv_to_json_first_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    my_dict = {}\n",
    "    with open(csv_file, encoding = 'latin1') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile)\n",
    "        #print(my_reader.fieldnames)\n",
    "        my_data = [my_row for my_row in my_reader]\n",
    "        for my_row in my_data:\n",
    "            #print(\"==\",my_row,\"==\",len(my_row),type(my_row))\n",
    "            my_dict = {}\n",
    "            i = 0\n",
    "            for my_key,my_val in my_row.items():\n",
    "                if my_key == 'PrÃ©nom et nom':\n",
    "                    data_dict[my_row[my_reader.fieldnames[i]]] = my_dict\n",
    "                else:\n",
    "                    my_dict[my_reader.fieldnames[i]] = my_row[my_reader.fieldnames[i]]\n",
    "                i = i+1\n",
    "\n",
    "          \n",
    "    #print(\"====================\")\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = data_dict\n",
    "    #\n",
    "    # convert both intermediary results to JSON object\n",
    "    #\n",
    "    y = dumps(my_my_dict)\n",
    "\n",
    "    return y\n",
    "\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "#\n",
    "# Dictionnaries intersection\n",
    "#\n",
    "def dict_intersect(*dicts):\n",
    "    comm_keys = dicts[0].keys()\n",
    "    for d in dicts[1:]:\n",
    "        # intersect keys first\n",
    "        comm_keys &= d.keys()\n",
    "    # then build a result dict with nested comprehension\n",
    "    result = {key:[d[key] for d in dicts] for key in comm_keys}\n",
    "    # if you choose the following representation, we keep less values. Why?\n",
    "    #result = {key:{d[key] for d in dicts} for key in comm_keys}\n",
    "    res = {}\n",
    "    for key,val in result.items():\n",
    "        #print(key,'==',val)\n",
    "        data_str = json.dumps(val, cls=SetEncoder)\n",
    "        #print(data_str)\n",
    "        res[key] = data_str\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def intersection(mc,id1,id2):\n",
    "\n",
    "    #print(type(mc),id1,id2)\n",
    "    doc1 = mc.find({'_id':id1})\n",
    "    doc2 = mc.find({'_id':id2})\n",
    "\n",
    "    # Second, iterate through dictionaries\n",
    "    d_res = {}\n",
    "    for d1 in doc1:\n",
    "        d11 = list(d1.keys())\n",
    "        res1 = d1\n",
    "        #print('==',d11,'==')\n",
    "    for d2 in doc2:\n",
    "        d22 = list(d2.keys())\n",
    "        res2 = d2\n",
    "        #print('==',d22,'==')\n",
    "    d_res = {}\n",
    "    for d_111 in d11:\n",
    "       for d_222 in d22:\n",
    "           if d_111 != '_id' and d_222 != '_id':\n",
    "               if d_111 == d_222:\n",
    "                   #d.update(res1[d_111])\n",
    "                   #d.update(res2[d_222])\n",
    "                   d_res[d_111] = dict_intersect(res1[d_111],res2[d_222])\n",
    "                   #print(\"**\",d_111,d_222,\"**\")\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = d_res\n",
    "\n",
    "    z = dumps(my_my_dict)\n",
    "\n",
    "    # Save the intersect in the collection\n",
    "    mc.insert_one(my_my_dict)\n",
    "\n",
    "    return z\n",
    "\n",
    "# Main program\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    mydb = client[\"mydatabase\"]\n",
    "    mycol = mydb[\"mycollection\"]\n",
    "\n",
    "   \n",
    "\n",
    "    from json import loads\n",
    "    from json import dumps\n",
    "\n",
    "    # First, transform json objects to dictionaries\n",
    "\n",
    "    d1_name = list(loads(json_one))[0]\n",
    "    #print(d1_name)\n",
    "    d2_name = list(loads(json_two))[0]\n",
    "    #print(d2_name)\n",
    "\n",
    "    d1 = loads(json_one)[d1_name]\n",
    "    d2 = loads(json_two)[d2_name]\n",
    "    #print(d1)\n",
    "    #print(d2)\n",
    "\n",
    "    # store them into MongoDB\n",
    "\n",
    "    #client.test_database.drop()\n",
    "    post_id_one = mycol.insert_one(d1).inserted_id\n",
    "    post_id_two = mycol.insert_one(d2).inserted_id\n",
    "\n",
    "    # compute the intersect\n",
    "    d = intersection (mycol,post_id_one,post_id_two)\n",
    "\n",
    "    # print the 3 documents in the collection\n",
    "    from pprint import pprint\n",
    "\n",
    "    cursor = mycol.find({})\n",
    "    for document in cursor:\n",
    "        pprint(document)\n",
    "\n",
    "    # On fait du mÃ©nage\n",
    "    mycol.drop()\n",
    "    client.drop_database('mydatabase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmzfrANMehN2"
   },
   "source": [
    "##**INDEX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYne2QPTge7X"
   },
   "source": [
    "En MongoDB, un index est une structure de données spéciale qui accélère les requêtes sur certains champs en facilitant la recherche de documents. Cependant, la création et la gestion des index peuvent entraîner des coûts supplémentaires en termes de mémoire et de performances d'écriture. Un index trie les valeurs des champs spécifiés, permettant à MongoDB de localiser rapidement les documents pertinents sans devoir parcourir l'intégralité de la collection.\n",
    "\n",
    "\n",
    "Les index sont stockés en mémoire (RAM) pour améliorer les performances, ce qui peut augmenter l'utilisation de la mémoire si plusieurs index sont créés. Des index mal optimisés ou inutiles peuvent aussi affecter négativement les performances globales, car leur maintenance devient coûteuse en ressources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjD9SPPQeI8Q",
    "outputId": "5fced028-86dc-47a2-e92f-2b460645e65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start performance eval over 14000 inputs\n",
      "CPU Execution time: 35.610781425999996 seconds\n",
      "We found 1509 duplicates in the input\n",
      "\n",
      "Wall time (also known as clock time or wall-clock time) is simply the total time\n",
      "elapsed during the measurement. Itâ€™s the time you can measure with a stopwatch.\n",
      "It is the difference between the time at which a program finished its execution and\n",
      "the time at which the program started. It also includes waiting time for resources.\n",
      "\n",
      "CPU Time, on the other hand, refers to the time the CPU was busy processing\n",
      "the programâ€™s instructions. The time spent waiting for other task to complete\n",
      "(like I/O operations) is not included in the CPU time. It does not include\n",
      "the waiting time for resources.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Performance of MongoDB with indexes\n",
    "#\n",
    "import csv\n",
    "from json import dumps\n",
    "import time\n",
    "\n",
    "def perf_mongo(csv_file, n):\n",
    "\n",
    "    from pymongo import MongoClient\n",
    "\n",
    "    mydb = client[\"mydatabase\"]\n",
    "    mycol = mydb[\"mycollection\"]\n",
    "    # Empty the collection\n",
    "    mycol.drop()\n",
    "    # Create an index for the collection\n",
    "    mycol.create_index([ ('M', 1) ])\n",
    "\n",
    "    with open(csv_file, encoding = 'utf-8') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile,delimiter='\\t')\n",
    "        my_data = [my_row for my_row in my_reader]\n",
    "        #print(my_data)\n",
    "        pres = dup = 0\n",
    "        print('Start performance eval over',n,'inputs')\n",
    "        # get the start time\n",
    "        st = time.process_time()\n",
    "        for my_row in my_data[0:n]:\n",
    "            # print(my_row['M'],type(my_row['M']))\n",
    "            #\n",
    "            # find and replace <=> test if key exists\n",
    "            #\n",
    "            mycol.replace_one({my_row['M']: 1},{my_row['M']:1},upsert=True,hint=[ ('M', 1) ])\n",
    "        # get the end time\n",
    "        et = time.process_time()\n",
    "        # get execution time\n",
    "        res = et - st\n",
    "        print('CPU Execution time:', res, 'seconds')\n",
    "        print('We found',n - mycol.count_documents({}),'duplicates in the input')\n",
    "        print()\n",
    "        print('Wall time (also known as clock time or wall-clock time) is simply the total time')\n",
    "        print('elapsed during the measurement. Itâ€™s the time you can measure with a stopwatch.')\n",
    "        print('It is the difference between the time at which a program finished its execution and')\n",
    "        print('the time at which the program started. It also includes waiting time for resources.')\n",
    "        print()\n",
    "        print('CPU Time, on the other hand, refers to the time the CPU was busy processing')\n",
    "        print('the programâ€™s instructions. The time spent waiting for other task to complete')\n",
    "        print('(like I/O operations) is not included in the CPU time. It does not include')\n",
    "        print('the waiting time for resources.')\n",
    "#Step 1\n",
    "\n",
    "perf_mongo(\"../data/DEMO.csv\", 14000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKaSrYW8wO50"
   },
   "source": [
    "##**AGREGATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnKiBl38wTOn"
   },
   "source": [
    "L'**agrégation** en MongoDB est un processus permettant de transformer et d'analyser des ensembles de documents via une série d'étapes dans une pipeline. Ces étapes, comme `$match`, `$group`, `$project`, et `$sort`, permettent de filtrer, regrouper, modifier, et trier les données pour obtenir des résultats spécifiques ou des résumés, tels que des statistiques et des rapports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmkBnQ7jwSXm",
    "outputId": "19086e62-2bde-4b04-fe18-829b532c7de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start performance eval over 100 inputs\n",
      "CPU Execution time: 0.09375 seconds\n",
      "\n",
      "Wall time (also known as clock time or wall-clock time) is simply the total time\n",
      "elapsed during the measurement. Itâ€™s the time you can measure with a stopwatch.\n",
      "It is the difference between the time at which a program finished its execution and\n",
      "the time at which the program started. It also includes waiting time for resources.\n",
      "\n",
      "CPU Time, on the other hand, refers to the time the CPU was busy processing\n",
      "the programâ€™s instructions. The time spent waiting for other task to complete\n",
      "(like I/O operations) is not included in the CPU time. It does not include\n",
      "the waiting time for resources.\n",
      "================================================\n",
      " Find all definition(s) for word \"Ã  cheval sur\" \n",
      "================================================\n",
      "{'_id': ObjectId('67366e6ccddcbbed4846a1b9'), 'M': 'à cheval sur', 'SENS': '(assis)à califourchon'}\n",
      "{'_id': ObjectId('67366e6ccddcbbed4846a1ba'), 'M': 'à cheval sur', 'SENS': 'intransigeant sr qc'}\n",
      "{'_id': ObjectId('67366e6ccddcbbed4846a1bb'), 'M': 'à cheval sur', 'SENS': 'ne pas transiger sur'}\n",
      "================================\n",
      " Number of definitions per word \n",
      "================================\n",
      "{'_id': 'a', 'Total': 2}\n",
      "{'_id': 'à bâtons rompus', 'Total': 1}\n",
      "{'_id': 'à côté', 'Total': 1}\n",
      "{'_id': 'à côté de ses pompes', 'Total': 1}\n",
      "{'_id': 'à bon droit', 'Total': 1}\n",
      "{'_id': 'à bout de souffle', 'Total': 1}\n",
      "{'_id': 'à bras raccourcis', 'Total': 1}\n",
      "{'_id': 'à califourchon', 'Total': 1}\n",
      "{'_id': 'à cet égard', 'Total': 1}\n",
      "{'_id': 'à bout de bras', 'Total': 2}\n",
      "{'_id': 'à cause que', 'Total': 1}\n",
      "{'_id': 'à bras tendus', 'Total': 1}\n",
      "{'_id': 'à courre', 'Total': 1}\n",
      "{'_id': 'à clin', 'Total': 1}\n",
      "{'_id': 'à bas', 'Total': 1}\n",
      "{'_id': 'à brève échéance', 'Total': 1}\n",
      "{'_id': 'à cet effet', 'Total': 1}\n",
      "{'_id': 'à ce point', 'Total': 1}\n",
      "{'_id': 'à contre-lit', 'Total': 1}\n",
      "{'_id': 'à cent pour cent', 'Total': 1}\n",
      "{'_id': 'à contresens', 'Total': 1}\n",
      "{'_id': 'à cocourant', 'Total': 1}\n",
      "{'_id': 'à côté de', 'Total': 2}\n",
      "{'_id': 'à aucun prix', 'Total': 1}\n",
      "{'_id': 'à charge', 'Total': 1}\n",
      "{'_id': 'à cela près', 'Total': 1}\n",
      "{'_id': 'à bureaux fermés', 'Total': 1}\n",
      "{'_id': 'à ces mots', 'Total': 1}\n",
      "{'_id': \"à cent sous de l'heure\", 'Total': 1}\n",
      "{'_id': 'à coucher dehors', 'Total': 1}\n",
      "{'_id': 'à bouche que veux-tu', 'Total': 1}\n",
      "{'_id': 'à ce titre', 'Total': 1}\n",
      "{'_id': 'à coups de cuiller à pot', 'Total': 1}\n",
      "{'_id': 'à aucun moment', 'Total': 1}\n",
      "{'_id': 'à corps perdu', 'Total': 1}\n",
      "{'_id': 'à coeur', 'Total': 1}\n",
      "{'_id': 'à bloc', 'Total': 1}\n",
      "{'_id': 'à', 'Total': 1}\n",
      "{'_id': \"à compte d'auteur\", 'Total': 1}\n",
      "{'_id': 'à contre-courant', 'Total': 1}\n",
      "{'_id': 'à bon prix', 'Total': 1}\n",
      "{'_id': 'à coeur ouvert', 'Total': 1}\n",
      "{'_id': 'à bon entendeur salut', 'Total': 1}\n",
      "{'_id': 'à confesse', 'Total': 1}\n",
      "{'_id': 'à cheval sur', 'Total': 3}\n",
      "{'_id': 'à claire-voie', 'Total': 1}\n",
      "{'_id': 'à cette fin que', 'Total': 1}\n",
      "{'_id': 'à contrecoeur', 'Total': 1}\n",
      "{'_id': 'à cor et à cri', 'Total': 1}\n",
      "{'_id': 'à bonne distance', 'Total': 1}\n",
      "{'_id': 'à coups de hache', 'Total': 1}\n",
      "{'_id': 'à bout portant', 'Total': 1}\n",
      "{'_id': 'a contrario', 'Total': 1}\n",
      "{'_id': 'à ce compte-là', 'Total': 1}\n",
      "{'_id': 'à bras', 'Total': 1}\n",
      "{'_id': 'à compter de tant', 'Total': 1}\n",
      "{'_id': 'à bref délai', 'Total': 1}\n",
      "{'_id': 'à brûle-pourpoint', 'Total': 1}\n",
      "{'_id': 'à ce régime', 'Total': 1}\n",
      "{'_id': 'à bout touchant', 'Total': 1}\n",
      "{'_id': 'à beaucoup près', 'Total': 1}\n",
      "{'_id': 'à bride abattue', 'Total': 1}\n",
      "{'_id': 'à cette date', 'Total': 1}\n",
      "{'_id': 'à charge de revanche', 'Total': 1}\n",
      "{'_id': 'à ce jour', 'Total': 1}\n",
      "{'_id': 'à contre-poil', 'Total': 1}\n",
      "{'_id': 'à chaque instant', 'Total': 1}\n",
      "{'_id': 'à coups de', 'Total': 1}\n",
      "{'_id': 'à ciel ouvert', 'Total': 1}\n",
      "{'_id': 'à bonne enseigne', 'Total': 1}\n",
      "{'_id': 'a capella', 'Total': 1}\n",
      "{'_id': 'à charge de', 'Total': 1}\n",
      "{'_id': 'à condition de', 'Total': 1}\n",
      "{'_id': 'à contre-bord', 'Total': 1}\n",
      "{'_id': 'à base de', 'Total': 1}\n",
      "{'_id': 'à condition que', 'Total': 2}\n",
      "{'_id': 'à bas prix', 'Total': 1}\n",
      "{'_id': 'à côté de la plaque', 'Total': 1}\n",
      "{'_id': 'à bout de course', 'Total': 1}\n",
      "{'_id': 'à bientôt', 'Total': 1}\n",
      "{'_id': 'à bon marché', 'Total': 2}\n",
      "{'_id': 'à boucheton', 'Total': 1}\n",
      "{'_id': 'à bras-le-corps', 'Total': 1}\n",
      "{'_id': 'à contre-passe', 'Total': 1}\n",
      "{'_id': 'à contretemps', 'Total': 1}\n",
      "{'_id': 'à chaud', 'Total': 1}\n",
      "{'_id': 'à bon escient', 'Total': 1}\n",
      "{'_id': 'à chaque pas', 'Total': 1}\n",
      "{'_id': 'à côté de ça', 'Total': 1}\n",
      "{'_id': 'à bras ouverts', 'Total': 1}\n",
      "{'_id': 'à bord de', 'Total': 1}\n",
      "{'_id': 'à coup sûr', 'Total': 1}\n",
      "{'_id': 'à cette heure', 'Total': 1}\n",
      "==============================\n",
      "    Merging of definitions\n",
      "==============================\n",
      "{'_id': 'à cette heure', 'meaning': ['maintenant']}\n",
      "{'_id': 'à bord de', 'meaning': ['ds véh,ds bateau']}\n",
      "{'_id': 'à bras ouverts', 'meaning': ['(accueilir)cordialement']}\n",
      "{'_id': 'à coup sûr', 'meaning': ['sûrement']}\n",
      "{'_id': 'à bon escient', 'meaning': ['(agir)à propos']}\n",
      "{'_id': 'à chaque pas', 'meaning': ['à chaque instant']}\n",
      "{'_id': 'à côté de ça', 'meaning': ['p ailleurs']}\n",
      "{'_id': 'à chaud', 'meaning': ['en pleine crise']}\n",
      "{'_id': 'à bientôt', 'meaning': ['au revoir']}\n",
      "{'_id': 'à bout de course', 'meaning': ['(qn)ê épuisé']}\n",
      "{'_id': 'à boucheton', 'meaning': ['façon d placer poterie']}\n",
      "{'_id': 'à bon marché', 'meaning': ['(vente/achat)à prix bas', 'ss grds inconvénients']}\n",
      "{'_id': 'à bras-le-corps', 'meaning': ['(tenir)au milieu d corp']}\n",
      "{'_id': 'à bas prix', 'meaning': ['(vendre)à bon marché']}\n",
      "{'_id': 'à contre-passe', 'meaning': ['d forme d sciage']}\n",
      "{'_id': 'à contretemps', 'meaning': ['mal à propos']}\n",
      "{'_id': 'à base de', 'meaning': ['d composant principal']}\n",
      "{'_id': 'à côté de la plaque', 'meaning': ['(ê)fou,hors sujet']}\n",
      "{'_id': 'à condition que', 'meaning': ['sous réserve que', 'sous réserve que']}\n",
      "{'_id': 'à contre-bord', 'meaning': [\"à l'opposé d autre\"]}\n",
      "{'_id': 'à ciel ouvert', 'meaning': [\"(ê)à l'air libre\"]}\n",
      "{'_id': 'a capella', 'meaning': ['ss accompagnement']}\n",
      "{'_id': 'à bonne enseigne', 'meaning': ['av solides granties']}\n",
      "{'_id': 'à chaque instant', 'meaning': ['continuellement']}\n",
      "{'_id': 'à charge de', 'meaning': [\"ds l'obligation de\"]}\n",
      "{'_id': 'à condition de', 'meaning': ['moyennant qc']}\n",
      "{'_id': 'à ce jour', 'meaning': [\"aujourd'hui\"]}\n",
      "{'_id': 'à bout touchant', 'meaning': ['(tirer)e touchant corps']}\n",
      "{'_id': 'à ce régime', 'meaning': ['en agissant ainsi']}\n",
      "{'_id': 'à cette date', 'meaning': ['à ce moment']}\n",
      "{'_id': 'à beaucoup près', 'meaning': ['à forte différence près']}\n",
      "{'_id': 'à bride abattue', 'meaning': ['à tte vitesse d cheval']}\n",
      "{'_id': 'à charge de revanche', 'meaning': ['en rendant même service']}\n",
      "{'_id': 'à brûle-pourpoint', 'meaning': ['d faç immédiate,brutale']}\n",
      "{'_id': 'à bref délai', 'meaning': ['ds peu d tps (durée)']}\n",
      "{'_id': 'à compter de tant', 'meaning': ['à dater de,depuis tps']}\n",
      "{'_id': 'à contre-poil', 'meaning': ['(aller)à sens opposé']}\n",
      "{'_id': 'à bras', 'meaning': ['(tenir)p force d bras']}\n",
      "{'_id': 'à ce compte-là', 'meaning': ['en conclusion']}\n",
      "{'_id': 'à coups de', 'meaning': ['en multipliant actes']}\n",
      "{'_id': 'à coups de hache', 'meaning': ['grossièrement']}\n",
      "{'_id': 'a contrario', 'meaning': [\"à l'inverse\"]}\n",
      "{'_id': 'à bout portant', 'meaning': ['(tirer)d sr très près']}\n",
      "{'_id': 'à cor et à cri', 'meaning': ['(crier)à grand bruit']}\n",
      "{'_id': 'à cette fin que', 'meaning': ['dans le but de,sue']}\n",
      "{'_id': 'à bonne distance', 'meaning': [\"(se tenir)à l'écart\"]}\n",
      "{'_id': 'à contrecoeur', 'meaning': ['à regret']}\n",
      "{'_id': 'à bon entendeur salut', 'meaning': ['avertissement donné à']}\n",
      "{'_id': 'à confesse', 'meaning': ['confession']}\n",
      "{'_id': 'à cheval sur', 'meaning': ['(assis)à califourchon', 'intransigeant sr qc', 'ne pas transiger sur']}\n",
      "{'_id': 'à claire-voie', 'meaning': ['(barrière)q p ê ouverte']}\n",
      "{'_id': \"à compte d'auteur\", 'meaning': [\"aux frais d l'auteur\"]}\n",
      "{'_id': 'à coeur ouvert', 'meaning': ['(parler)franchement']}\n",
      "{'_id': 'à bon prix', 'meaning': ['(acheter)bon marché']}\n",
      "{'_id': 'à bloc', 'meaning': ['à fond,au maximum']}\n",
      "{'_id': 'à', 'meaning': ['(qc)appartenir à qn,qc / à N (ê)']}\n",
      "{'_id': 'à contre-courant', 'meaning': ['(aller)en sens opposé']}\n",
      "{'_id': 'à corps perdu', 'meaning': ['en prenant ts risques']}\n",
      "{'_id': 'à aucun moment', 'meaning': ['jamais']}\n",
      "{'_id': 'à coeur', 'meaning': [\"jusqu'au centre d aliment\"]}\n",
      "{'_id': 'à bouche que veux-tu', 'meaning': ['(donner)à profusion']}\n",
      "{'_id': 'à ce titre', 'meaning': ['pr cette raison']}\n",
      "{'_id': 'à bureaux fermés', 'meaning': ['ss nveaux assistants']}\n",
      "{'_id': 'à coucher dehors', 'meaning': ['(nom)imprononçable']}\n",
      "{'_id': \"à cent sous de l'heure\", 'meaning': ['énormément']}\n",
      "{'_id': 'à charge', 'meaning': [\"q relève d l'auteur\"]}\n",
      "{'_id': 'à aucun prix', 'meaning': ['(céder)en aucun cas']}\n",
      "{'_id': 'à cela près', 'meaning': ['approximation']}\n",
      "{'_id': 'à ces mots', 'meaning': ['après av entend cela']}\n",
      "{'_id': 'à cocourant', 'meaning': ['(aller)ds le même sens']}\n",
      "{'_id': 'à coups de cuiller à pot', 'meaning': ['très rapidement']}\n",
      "{'_id': 'à ce point', 'meaning': ['à tel degré élevé']}\n",
      "{'_id': 'à cet effet', 'meaning': ['en vue d cela']}\n",
      "{'_id': 'à cent pour cent', 'meaning': ['complètement,totalement']}\n",
      "{'_id': 'à contre-lit', 'meaning': ['(bloc,pierre)en délit']}\n",
      "{'_id': 'à contresens', 'meaning': ['(aller)en sens contrair']}\n",
      "{'_id': 'à bas', 'meaning': ['hostilité à N']}\n",
      "{'_id': 'à côté de', 'meaning': ['(aller)auprès de', 'en comparaison de']}\n",
      "{'_id': 'à brève échéance', 'meaning': ['ds peu d tps (date)']}\n",
      "{'_id': 'à bras tendus', 'meaning': ['bras écartés et tendus']}\n",
      "{'_id': 'à courre', 'meaning': ['(chasse)à la poursuite']}\n",
      "{'_id': 'à clin', 'meaning': ['d type revêtement']}\n",
      "{'_id': 'à cause que', 'meaning': ['cause,explication']}\n",
      "{'_id': 'à bout de bras', 'meaning': ['tenir av effort pr aide', '(tenir)qc à bras tendu']}\n",
      "{'_id': 'à bon droit', 'meaning': ['(réclamer)en tte justice']}\n",
      "{'_id': 'à bras raccourcis', 'meaning': ['d ttes forces des bras']}\n",
      "{'_id': 'à califourchon', 'meaning': ['(assis)jambe d chaq côt']}\n",
      "{'_id': 'à bout de souffle', 'meaning': ['(qn)ê épuisé']}\n",
      "{'_id': 'à cet égard', 'meaning': ['sr ce point,à ce sujet']}\n",
      "{'_id': 'à côté de ses pompes', 'meaning': ['(ê)fou,désorienté']}\n",
      "{'_id': 'à côté', 'meaning': ['(ê)à proximité']}\n",
      "{'_id': 'a', 'meaning': ['alphabet latin', 'ouverte']}\n",
      "{'_id': 'à bâtons rompus', 'meaning': ['ss suite,d f discontinu']}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from json import dumps\n",
    "import time\n",
    "\n",
    "def perf_mongo(csv_file, n):\n",
    "\n",
    "    from pymongo import MongoClient\n",
    "\n",
    "    mydb = client[\"mydatabase\"  ]\n",
    "    mycol = mydb[\"mycollection\"]\n",
    "    # Empty the collection\n",
    "    mycol.drop()\n",
    "    # Create an index for the collection\n",
    "    mycol.create_index([ ('M', 1) ])\n",
    "\n",
    "    with open(csv_file, encoding = 'utf-8') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile,delimiter='\\t')\n",
    "        my_data = [my_row for my_row in my_reader]\n",
    "        #print(my_data)\n",
    "        pres = dup = 0\n",
    "        print('Start performance eval over',n,'inputs')\n",
    "        # get the start time\n",
    "        st = time.process_time()\n",
    "        for my_row in my_data[0:n]:\n",
    "            # print(my_row['M'],type(my_row['SENS']))\n",
    "            #\n",
    "            # insert {\"M\": my_row['M'], \"SENS\": my_row['SENS'] }\n",
    "            #\n",
    "            mycol.insert_one({\"M\": my_row['M'], \"SENS\": my_row['SENS'] })\n",
    "        # get the end time\n",
    "        et = time.process_time()\n",
    "        # get execution time\n",
    "        res = et - st\n",
    "        print('CPU Execution time:', res, 'seconds')\n",
    "        print()\n",
    "        print('Wall time (also known as clock time or wall-clock time) is simply the total time')\n",
    "        print('elapsed during the measurement. Itâ€™s the time you can measure with a stopwatch.')\n",
    "        print('It is the difference between the time at which a program finished its execution and')\n",
    "        print('the time at which the program started. It also includes waiting time for resources.')\n",
    "        print()\n",
    "        print('CPU Time, on the other hand, refers to the time the CPU was busy processing')\n",
    "        print('the programâ€™s instructions. The time spent waiting for other task to complete')\n",
    "        print('(like I/O operations) is not included in the CPU time. It does not include')\n",
    "        print('the waiting time for resources.')\n",
    "\n",
    "        #\n",
    "        # We search all entries for word 'Ã  cheval sur'\n",
    "        #\n",
    "        print('================================================')\n",
    "        print(' Find all definition(s) for word \"Ã  cheval sur\" ')\n",
    "        print('================================================')\n",
    "\n",
    "        # Recherche d'un mot spécifique sans $where\n",
    "        word_to_find = \"à cheval sur\"  # corriger l'encodage si nécessaire\n",
    "        for doc in mycol.find({\"M\": word_to_find}):\n",
    "            print(doc)\n",
    "\n",
    "\n",
    "        #\n",
    "        # We compute the number of definition for each word\n",
    "        #\n",
    "        agg_result = mycol.aggregate(\n",
    "            [{\n",
    "                \"$group\" :\n",
    "                {\"_id\" : \"$M\",\n",
    "                 \"Total\" : {\"$sum\" : 1}\n",
    "                 }}\n",
    "             ])\n",
    "        print('================================')\n",
    "        print(\" Number of definitions per word \")\n",
    "        print('================================')\n",
    "        for i in agg_result:\n",
    "            print(i)\n",
    "\n",
    "        #\n",
    "        # We merge all the definition of a word\n",
    "        #\n",
    "        agg_result = mycol.aggregate(\n",
    "            [  { \"$sort\": { \"M\": 1 } },\n",
    "               {\n",
    "                   \"$group\":\n",
    "                               {\n",
    "                                   \"_id\": \"$M\",\n",
    "                                   #\"meaning\": { \"$push\":  { \"item\": \"$SENS\" } }\n",
    "                                   \"meaning\": { \"$push\":  \"$SENS\" }\n",
    "                               }\n",
    "               }\n",
    "             ]\n",
    "        )\n",
    "        print('==============================')\n",
    "        print(\"    Merging of definitions\")\n",
    "        print('==============================')\n",
    "        for i in agg_result:\n",
    "            print(i)\n",
    "\n",
    "\n",
    "#Step 1\n",
    "\n",
    "perf_mongo(\"../data/DEMO.csv\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhFkXYYf2hiM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Recherche d'un mot spécifique sans $where\n",
    "word_to_find = \"à cheval sur\"  # corriger l'encodage si nécessaire\n",
    "for doc in mycol.find({\"M\": word_to_find}):\n",
    "    print(doc)\n",
    "\n",
    "reformulation faite pour que le code marche\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ycDscc684HI",
    "outputId": "3619c54b-2057-466b-f586-efaddd3cd1aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type agrÃ©gation: <class 'pymongo.synchronous.command_cursor.CommandCursor'>\n",
      "=====  AgrÃ©gation  =====\n",
      "{'Detail': [{'Nom': 'HervÃ© P',\n",
      "             'T_1': '10.00 / 16',\n",
      "             'T_2': '12.00 / 18',\n",
      "             'T_3': '10.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1ed')}],\n",
      " 'Prenom_nom': 'HervÃ© P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1df')}\n",
      "{'Detail': [{'Nom': 'Laurent H',\n",
      "             'T_1': '15.00 / 16',\n",
      "             'T_2': '12.00 / 18',\n",
      "             'T_3': '7.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1ee')}],\n",
      " 'Prenom_nom': 'Laurent H',\n",
      " 'Test_1': '15.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e0')}\n",
      "{'Detail': [{'Nom': 'Destin L',\n",
      "             'T_1': '11.00 / 16',\n",
      "             'T_2': '7.00 / 18',\n",
      "             'T_3': '8.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1ef')}],\n",
      " 'Prenom_nom': 'Destin L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e1')}\n",
      "{'Detail': [{'Nom': 'Guillaume C',\n",
      "             'T_1': '10.00 / 16',\n",
      "             'T_2': '4.00 / 18',\n",
      "             'T_3': '10.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f0')}],\n",
      " 'Prenom_nom': 'Guillaume C',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '4.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e2')}\n",
      "{'Detail': [{'Nom': 'Haytem D',\n",
      "             'T_1': '12.00 / 16',\n",
      "             'T_2': '7.00 / 18',\n",
      "             'T_3': '10.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f1')}],\n",
      " 'Prenom_nom': 'Haytem D',\n",
      " 'Test_1': '12.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e3')}\n",
      "{'Detail': [{'Nom': 'Cam Chau N',\n",
      "             'T_1': '6.00 / 16',\n",
      "             'T_2': '9.00 / 18',\n",
      "             'T_3': '12.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f2')}],\n",
      " 'Prenom_nom': 'Cam Chau N',\n",
      " 'Test_1': '6.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e4')}\n",
      "{'Detail': [{'Nom': 'Sarra Z',\n",
      "             'T_1': '11.00 / 16',\n",
      "             'T_2': '6.00 / 18',\n",
      "             'T_3': '15.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f3')}],\n",
      " 'Prenom_nom': 'Sarra Z',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '6.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e5')}\n",
      "{'Detail': [{'Nom': 'Romulus L',\n",
      "             'T_1': '11.00 / 16',\n",
      "             'T_2': '11.00 / 18',\n",
      "             'T_3': '14.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f4')}],\n",
      " 'Prenom_nom': 'Romulus L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e6')}\n",
      "{'Detail': [{'Nom': 'Thierno D',\n",
      "             'T_1': '5.00 / 16',\n",
      "             'T_2': '8.00 / 18',\n",
      "             'T_3': '13.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f5')}],\n",
      " 'Prenom_nom': 'Thierno D',\n",
      " 'Test_1': '5.00 / 16',\n",
      " 'Test_2': '8.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e7')}\n",
      "{'Detail': [{'Nom': 'Rosenthal Preston R',\n",
      "             'T_1': '13.00 / 16',\n",
      "             'T_2': '13.00 / 18',\n",
      "             'T_3': '11.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f6')}],\n",
      " 'Prenom_nom': 'Rosenthal Preston R',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '13.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e8')}\n",
      "{'Detail': [{'Nom': 'Betty T',\n",
      "             'T_1': '11.00 / 16',\n",
      "             'T_2': '11.00 / 18',\n",
      "             'T_3': '5.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f7')}],\n",
      " 'Prenom_nom': 'Betty T',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1e9')}\n",
      "{'Detail': [{'Nom': 'Mouloud B',\n",
      "             'T_1': '13.00 / 16',\n",
      "             'T_2': '17.00 / 18',\n",
      "             'T_3': '4.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f8')}],\n",
      " 'Prenom_nom': 'Mouloud B',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '17.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1ea')}\n",
      "{'Detail': [{'Nom': 'Joseph L',\n",
      "             'T_1': '11.00 / 16',\n",
      "             'T_2': '11.00 / 18',\n",
      "             'T_3': '8.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1f9')}],\n",
      " 'Prenom_nom': 'Joseph L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1eb')}\n",
      "{'Detail': [{'Nom': 'Nataliya P',\n",
      "             'T_1': '10.00 / 16',\n",
      "             'T_2': '9.00 / 18',\n",
      "             'T_3': '9.00 / 18',\n",
      "             '_id': ObjectId('67366ebecddcbbed4846a1fa')}],\n",
      " 'Prenom_nom': 'Nataliya P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366ebecddcbbed4846a1ec')}\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "\n",
    "client.drop_database('mydatabase')\n",
    "\n",
    "db = client[\"mydatabase\"]\n",
    "\n",
    "#Create 'Books' collection\n",
    "db.Matiere1.insert_many([\n",
    "    { 'Test_2':'12.00 / 18','Test_1':'10.00 / 16','Prenom_nom':'HervÃ© P' },\n",
    "    { 'Test_2':'12.00 / 18','Test_1':'15.00 / 16','Prenom_nom':'Laurent H' },\n",
    "    { 'Test_2':'7.00 / 18','Test_1':'11.00 / 16','Prenom_nom':'Destin L' },\n",
    "    { 'Test_2':'4.00 / 18','Test_1':'10.00 / 16','Prenom_nom':'Guillaume C' },\n",
    "    { 'Test_2':'7.00 / 18','Test_1':'12.00 / 16','Prenom_nom':'Haytem D' },\n",
    "    { 'Test_2':'9.00 / 18','Test_1':'6.00 / 16','Prenom_nom':'Cam Chau N' },\n",
    "    { 'Test_2':'6.00 / 18','Test_1':'11.00 / 16','Prenom_nom':'Sarra Z' },\n",
    "    { 'Test_2':'11.00 / 18','Test_1':'11.00 / 16','Prenom_nom':'Romulus L' },\n",
    "    { 'Test_2':'8.00 / 18','Test_1':'5.00 / 16','Prenom_nom':'Thierno D' },\n",
    "    { 'Test_2':'13.00 / 18','Test_1':'13.00 / 16','Prenom_nom':'Rosenthal Preston R' },\n",
    "    { 'Test_2':'11.00 / 18','Test_1':'11.00 / 16','Prenom_nom':'Betty T' },\n",
    "    { 'Test_2':'17.00 / 18','Test_1':'13.00 / 16','Prenom_nom':'Mouloud B' },\n",
    "    { 'Test_2':'11.00 / 18','Test_1':'11.00 / 16','Prenom_nom':'Joseph L' },\n",
    "    { 'Test_2':'9.00 / 18','Test_1':'10.00 / 16','Prenom_nom':'Nataliya P' }\n",
    " ])\n",
    "\n",
    "#Create 'Authors' collection\n",
    "db.Matiere2.insert_many([\n",
    "    { 'T_3':'10.00 / 18','T_2':'12.00 / 18','T_1':'10.00 / 16','Nom':'HervÃ© P' },\n",
    "    { 'T_3':'7.00 / 18','T_2':'12.00 / 18','T_1':'15.00 / 16','Nom':'Laurent H' },\n",
    "    { 'T_3':'8.00 / 18','T_2':'7.00 / 18','T_1':'11.00 / 16','Nom':'Destin L' },\n",
    "    { 'T_3':'10.00 / 18','T_2':'4.00 / 18','T_1':'10.00 / 16','Nom':'Guillaume C' },\n",
    "    { 'T_3':'10.00 / 18','T_2':'7.00 / 18','T_1':'12.00 / 16','Nom':'Haytem D' },\n",
    "    { 'T_3':'12.00 / 18','T_2':'9.00 / 18','T_1':'6.00 / 16','Nom':'Cam Chau N' },\n",
    "    { 'T_3':'15.00 / 18','T_2':'6.00 / 18','T_1':'11.00 / 16','Nom':'Sarra Z' },\n",
    "    { 'T_3':'14.00 / 18','T_2':'11.00 / 18','T_1':'11.00 / 16','Nom':'Romulus L' },\n",
    "    { 'T_3':'13.00 / 18','T_2':'8.00 / 18','T_1':'5.00 / 16','Nom':'Thierno D' },\n",
    "    { 'T_3':'11.00 / 18','T_2':'13.00 / 18','T_1':'13.00 / 16','Nom':'Rosenthal Preston R' },\n",
    "    { 'T_3':'5.00 / 18','T_2':'11.00 / 18','T_1':'11.00 / 16','Nom':'Betty T' },\n",
    "    { 'T_3':'4.00 / 18','T_2':'17.00 / 18','T_1':'13.00 / 16','Nom':'Mouloud B' },\n",
    "    { 'T_3':'8.00 / 18','T_2':'11.00 / 18','T_1':'11.00 / 16','Nom':'Joseph L' },\n",
    "    { 'T_3':'9.00 / 18','T_2':'9.00 / 18','T_1':'10.00 / 16','Nom':'Nataliya P' }\n",
    " ])\n",
    "\n",
    "# Join two collections using $lookup operator\n",
    "agg_result = db.Matiere1.aggregate([\n",
    "   {\n",
    "      \"$lookup\":\n",
    "         {\n",
    "           \"from\": \"Matiere2\",\n",
    "           \"localField\": \"Prenom_nom\",\n",
    "           \"foreignField\": \"Nom\",\n",
    "           \"as\": \"Detail\"\n",
    "         }\n",
    "   }\n",
    "])\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"Type agrÃ©gation:\",type(agg_result))\n",
    "\n",
    "print(\"=====  AgrÃ©gation  =====\")\n",
    "for i in agg_result:\n",
    "    pprint(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcgWkOMy8_Ri",
    "outputId": "8ce77ca9-5264-4ec8-e060-84c53aee7eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type agrÃ©gation: <class 'pymongo.synchronous.command_cursor.CommandCursor'>\n",
      "=====  AgrÃ©gation  =====\n",
      "{'Prenom_nom': 'Hervé P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fb'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Laurent H',\n",
      " 'Test_1': '15.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fc'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Destin L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fd'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Guillaume C',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '4.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fe'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Haytem D',\n",
      " 'Test_1': '12.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1ff'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Cam Chau N',\n",
      " 'Test_1': '6.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a200'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Sarra Z',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '6.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a201'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Romulus L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a202'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Thierno D',\n",
      " 'Test_1': '5.00 / 16',\n",
      " 'Test_2': '8.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a203'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Rosenthal Preston R',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '13.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a204'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Betty T',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a205'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Mouloud B',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '17.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a206'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Joseph L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a207'),\n",
      " 'join_sample': []}\n",
      "{'Prenom_nom': 'Nataliya P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a208'),\n",
      " 'join_sample': []}\n",
      "===== Collection 1 =====\n",
      "{'Prenom_nom': 'Hervé P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fb')}\n",
      "{'Prenom_nom': 'Laurent H',\n",
      " 'Test_1': '15.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fc')}\n",
      "{'Prenom_nom': 'Destin L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fd')}\n",
      "{'Prenom_nom': 'Guillaume C',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '4.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1fe')}\n",
      "{'Prenom_nom': 'Haytem D',\n",
      " 'Test_1': '12.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a1ff')}\n",
      "{'Prenom_nom': 'Cam Chau N',\n",
      " 'Test_1': '6.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a200')}\n",
      "{'Prenom_nom': 'Sarra Z',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '6.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a201')}\n",
      "{'Prenom_nom': 'Romulus L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a202')}\n",
      "{'Prenom_nom': 'Thierno D',\n",
      " 'Test_1': '5.00 / 16',\n",
      " 'Test_2': '8.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a203')}\n",
      "{'Prenom_nom': 'Rosenthal Preston R',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '13.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a204')}\n",
      "{'Prenom_nom': 'Betty T',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a205')}\n",
      "{'Prenom_nom': 'Mouloud B',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '17.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a206')}\n",
      "{'Prenom_nom': 'Joseph L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a207')}\n",
      "{'Prenom_nom': 'Nataliya P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a208')}\n",
      "===== Collection 2 =====\n",
      "{'Nom': 'Hervé P',\n",
      " 'T_1': '10.00 / 16',\n",
      " 'T_2': '12.00 / 18',\n",
      " 'T_3': '10.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a209')}\n",
      "{'Nom': 'Laurent H',\n",
      " 'T_1': '15.00 / 16',\n",
      " 'T_2': '12.00 / 18',\n",
      " 'T_3': '7.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a20a')}\n",
      "{'Nom': 'Destin L',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '7.00 / 18',\n",
      " 'T_3': '8.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a20b')}\n",
      "{'Nom': 'Guillaume C',\n",
      " 'T_1': '10.00 / 16',\n",
      " 'T_2': '4.00 / 18',\n",
      " 'T_3': '10.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a20c')}\n",
      "{'Nom': 'Haytem D',\n",
      " 'T_1': '12.00 / 16',\n",
      " 'T_2': '7.00 / 18',\n",
      " 'T_3': '10.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a20d')}\n",
      "{'Nom': 'Cam Chau N',\n",
      " 'T_1': '6.00 / 16',\n",
      " 'T_2': '9.00 / 18',\n",
      " 'T_3': '12.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a20e')}\n",
      "{'Nom': 'Sarra Z',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '6.00 / 18',\n",
      " 'T_3': '15.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a20f')}\n",
      "{'Nom': 'Romulus L',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '11.00 / 18',\n",
      " 'T_3': '14.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a210')}\n",
      "{'Nom': 'Thierno D',\n",
      " 'T_1': '5.00 / 16',\n",
      " 'T_2': '8.00 / 18',\n",
      " 'T_3': '13.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a211')}\n",
      "{'Nom': 'Rosenthal Preston R',\n",
      " 'T_1': '13.00 / 16',\n",
      " 'T_2': '13.00 / 18',\n",
      " 'T_3': '11.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a212')}\n",
      "{'Nom': 'Betty T',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '11.00 / 18',\n",
      " 'T_3': '5.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a213')}\n",
      "{'Nom': 'Mouloud B',\n",
      " 'T_1': '13.00 / 16',\n",
      " 'T_2': '17.00 / 18',\n",
      " 'T_3': '4.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a214')}\n",
      "{'Nom': 'Joseph L',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '11.00 / 18',\n",
      " 'T_3': '8.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a215')}\n",
      "{'Nom': 'Nataliya P',\n",
      " 'T_1': '10.00 / 16',\n",
      " 'T_2': '9.00 / 18',\n",
      " 'T_3': '9.00 / 18',\n",
      " '_id': ObjectId('67366eefcddcbbed4846a216')}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json_first_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    my_dict = {}\n",
    "    with open(csv_file, encoding = 'latin1') as csvfile:\n",
    "        my_reader = csv.DictReader(csvfile)\n",
    "        #print(my_reader.fieldnames)\n",
    "        my_data = [my_row for my_row in my_reader]\n",
    "        for my_row in my_data:\n",
    "            #print(\"==\",my_row,\"==\",len(my_row),type(my_row))\n",
    "            my_dict = {}\n",
    "            i = 0\n",
    "            for my_key,my_val in my_row.items():\n",
    "                if my_key == 'PrÃ©nom et nom':\n",
    "                    data_dict[my_row[my_reader.fieldnames[i]]] = my_dict\n",
    "                else:\n",
    "                    my_dict[my_reader.fieldnames[i]] = my_row[my_reader.fieldnames[i]]\n",
    "                i = i+1\n",
    "\n",
    "    my_my_dict = {}\n",
    "    my_my_dict['test'] = data_dict\n",
    "    #\n",
    "    # convert both intermediary results to JSON object\n",
    "    #\n",
    "    y = dumps(my_my_dict)\n",
    "\n",
    "    return y\n",
    "\n",
    "def csv_to_json_second_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    csv_rows = []\n",
    "    #open a csv file handlerh\n",
    "    with open(csv_file, encoding = 'latin1', newline='') as csv_file_handler:\n",
    "        csv_reader = csv.DictReader(csv_file_handler)\n",
    "        field = csv_reader.fieldnames\n",
    "        for row in csv_reader:\n",
    "            #print([{field[i]:row[field[i]] for i in range(len(field))}])\n",
    "            csv_rows.extend([{field[i]:row[field[i]] for i in range(len(field))}])\n",
    "\n",
    "    z = dumps(csv_rows)\n",
    "   \n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "# Main program\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    from pymongo import MongoClient\n",
    "\n",
    "    mydb = client[\"mydatabase\"]\n",
    "    mycol_one = mydb[\"mycollection_one\"]\n",
    "    mycol_two = mydb[\"mycollection_two\"]\n",
    "\n",
    "    json_one = csv_to_json_second_method(\"../data/test_join.csv\")\n",
    "    json_two = csv_to_json_second_method(\"../data/test2_join.csv\")\n",
    "\n",
    "    from json import loads\n",
    "    from json import dumps\n",
    "\n",
    "    # First, transform json objects to dictionaries\n",
    "\n",
    "    d1_name = list(loads(json_one))\n",
    "    #print(d1_name)\n",
    "    d2_name = list(loads(json_two))\n",
    "    #print(d2_name)\n",
    "\n",
    "    #for row in d1_name:\n",
    "    #    mycol_one.insert_one(row)\n",
    "    mycol_one.insert_many(d1_name)\n",
    "\n",
    "    #for row in d2_name:\n",
    "    #    mycol_two.insert_one(row)\n",
    "    mycol_two.insert_many(d2_name)\n",
    "\n",
    "    # compute the join with the lookup aggregation\n",
    "    agg_result = mycol_one.aggregate([\n",
    "        {\n",
    "            '$lookup': {\n",
    "                'from': 'mycol_two',\n",
    "                'localField': 'Prenom_nom',\n",
    "                'foreignField': 'Nom',\n",
    "                'as': 'join_sample'\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    # print the 3 documents in the collection\n",
    "    from pprint import pprint\n",
    "\n",
    "    print(\"Type agrÃ©gation:\",type(agg_result))\n",
    "\n",
    "    print(\"=====  AgrÃ©gation  =====\")\n",
    "    for i in agg_result:\n",
    "        pprint(i)\n",
    "\n",
    "    print(\"===== Collection 1 =====\")\n",
    "    for i in mycol_one.find({}):\n",
    "        pprint(i)\n",
    "\n",
    "    print(\"===== Collection 2 =====\")\n",
    "    for i in mycol_two.find({}):\n",
    "        pprint(i)\n",
    "\n",
    "    # On fait du mÃ©nage\n",
    "    mycol_one.drop()\n",
    "    mycol_two.drop()\n",
    "    client.drop_database('mydatabase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu9FjhI4_3K9"
   },
   "source": [
    "Le problème  réside dans l'utilisation des champs pour la jointure. Dans l'agrégation, on a spécifié localField comme Prenom_nom et foreignField comme Nom. Pour que la jointure réussisse, les valeurs dans ces deux champs doivent correspondre. Si les valeurs ne correspondent pas, l'attribut join_sample dans les résultats de l'agrégation sera vide ce qui est le cas de code\n",
    "\n",
    "\n",
    "Voici une version corrigée du code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBV8bElW97eB",
    "outputId": "4309b359-eba3-4364-a213-0d3f1a0c8c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Collection 1 =====\n",
      "{'Prenom_nom': 'Hervé P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a217')}\n",
      "{'Prenom_nom': 'Laurent H',\n",
      " 'Test_1': '15.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a218')}\n",
      "{'Prenom_nom': 'Destin L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a219')}\n",
      "{'Prenom_nom': 'Guillaume C',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '4.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21a')}\n",
      "{'Prenom_nom': 'Haytem D',\n",
      " 'Test_1': '12.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21b')}\n",
      "{'Prenom_nom': 'Cam Chau N',\n",
      " 'Test_1': '6.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21c')}\n",
      "{'Prenom_nom': 'Sarra Z',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '6.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21d')}\n",
      "{'Prenom_nom': 'Romulus L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21e')}\n",
      "{'Prenom_nom': 'Thierno D',\n",
      " 'Test_1': '5.00 / 16',\n",
      " 'Test_2': '8.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21f')}\n",
      "{'Prenom_nom': 'Rosenthal Preston R',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '13.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a220')}\n",
      "{'Prenom_nom': 'Betty T',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a221')}\n",
      "{'Prenom_nom': 'Mouloud B',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '17.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a222')}\n",
      "{'Prenom_nom': 'Joseph L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a223')}\n",
      "{'Prenom_nom': 'Nataliya P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a224')}\n",
      "===== Collection 2 =====\n",
      "{'Nom': 'Hervé P',\n",
      " 'T_1': '10.00 / 16',\n",
      " 'T_2': '12.00 / 18',\n",
      " 'T_3': '10.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a225')}\n",
      "{'Nom': 'Laurent H',\n",
      " 'T_1': '15.00 / 16',\n",
      " 'T_2': '12.00 / 18',\n",
      " 'T_3': '7.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a226')}\n",
      "{'Nom': 'Destin L',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '7.00 / 18',\n",
      " 'T_3': '8.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a227')}\n",
      "{'Nom': 'Guillaume C',\n",
      " 'T_1': '10.00 / 16',\n",
      " 'T_2': '4.00 / 18',\n",
      " 'T_3': '10.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a228')}\n",
      "{'Nom': 'Haytem D',\n",
      " 'T_1': '12.00 / 16',\n",
      " 'T_2': '7.00 / 18',\n",
      " 'T_3': '10.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a229')}\n",
      "{'Nom': 'Cam Chau N',\n",
      " 'T_1': '6.00 / 16',\n",
      " 'T_2': '9.00 / 18',\n",
      " 'T_3': '12.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a22a')}\n",
      "{'Nom': 'Sarra Z',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '6.00 / 18',\n",
      " 'T_3': '15.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a22b')}\n",
      "{'Nom': 'Romulus L',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '11.00 / 18',\n",
      " 'T_3': '14.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a22c')}\n",
      "{'Nom': 'Thierno D',\n",
      " 'T_1': '5.00 / 16',\n",
      " 'T_2': '8.00 / 18',\n",
      " 'T_3': '13.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a22d')}\n",
      "{'Nom': 'Rosenthal Preston R',\n",
      " 'T_1': '13.00 / 16',\n",
      " 'T_2': '13.00 / 18',\n",
      " 'T_3': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a22e')}\n",
      "{'Nom': 'Betty T',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '11.00 / 18',\n",
      " 'T_3': '5.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a22f')}\n",
      "{'Nom': 'Mouloud B',\n",
      " 'T_1': '13.00 / 16',\n",
      " 'T_2': '17.00 / 18',\n",
      " 'T_3': '4.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a230')}\n",
      "{'Nom': 'Joseph L',\n",
      " 'T_1': '11.00 / 16',\n",
      " 'T_2': '11.00 / 18',\n",
      " 'T_3': '8.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a231')}\n",
      "{'Nom': 'Nataliya P',\n",
      " 'T_1': '10.00 / 16',\n",
      " 'T_2': '9.00 / 18',\n",
      " 'T_3': '9.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a232')}\n",
      "===== Agrégation =====\n",
      "{'Prenom_nom': 'Hervé P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a217'),\n",
      " 'join_sample': [{'Nom': 'Hervé P',\n",
      "                  'T_1': '10.00 / 16',\n",
      "                  'T_2': '12.00 / 18',\n",
      "                  'T_3': '10.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a225')}]}\n",
      "{'Prenom_nom': 'Laurent H',\n",
      " 'Test_1': '15.00 / 16',\n",
      " 'Test_2': '12.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a218'),\n",
      " 'join_sample': [{'Nom': 'Laurent H',\n",
      "                  'T_1': '15.00 / 16',\n",
      "                  'T_2': '12.00 / 18',\n",
      "                  'T_3': '7.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a226')}]}\n",
      "{'Prenom_nom': 'Destin L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a219'),\n",
      " 'join_sample': [{'Nom': 'Destin L',\n",
      "                  'T_1': '11.00 / 16',\n",
      "                  'T_2': '7.00 / 18',\n",
      "                  'T_3': '8.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a227')}]}\n",
      "{'Prenom_nom': 'Guillaume C',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '4.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21a'),\n",
      " 'join_sample': [{'Nom': 'Guillaume C',\n",
      "                  'T_1': '10.00 / 16',\n",
      "                  'T_2': '4.00 / 18',\n",
      "                  'T_3': '10.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a228')}]}\n",
      "{'Prenom_nom': 'Haytem D',\n",
      " 'Test_1': '12.00 / 16',\n",
      " 'Test_2': '7.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21b'),\n",
      " 'join_sample': [{'Nom': 'Haytem D',\n",
      "                  'T_1': '12.00 / 16',\n",
      "                  'T_2': '7.00 / 18',\n",
      "                  'T_3': '10.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a229')}]}\n",
      "{'Prenom_nom': 'Cam Chau N',\n",
      " 'Test_1': '6.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21c'),\n",
      " 'join_sample': [{'Nom': 'Cam Chau N',\n",
      "                  'T_1': '6.00 / 16',\n",
      "                  'T_2': '9.00 / 18',\n",
      "                  'T_3': '12.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a22a')}]}\n",
      "{'Prenom_nom': 'Sarra Z',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '6.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21d'),\n",
      " 'join_sample': [{'Nom': 'Sarra Z',\n",
      "                  'T_1': '11.00 / 16',\n",
      "                  'T_2': '6.00 / 18',\n",
      "                  'T_3': '15.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a22b')}]}\n",
      "{'Prenom_nom': 'Romulus L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21e'),\n",
      " 'join_sample': [{'Nom': 'Romulus L',\n",
      "                  'T_1': '11.00 / 16',\n",
      "                  'T_2': '11.00 / 18',\n",
      "                  'T_3': '14.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a22c')}]}\n",
      "{'Prenom_nom': 'Thierno D',\n",
      " 'Test_1': '5.00 / 16',\n",
      " 'Test_2': '8.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a21f'),\n",
      " 'join_sample': [{'Nom': 'Thierno D',\n",
      "                  'T_1': '5.00 / 16',\n",
      "                  'T_2': '8.00 / 18',\n",
      "                  'T_3': '13.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a22d')}]}\n",
      "{'Prenom_nom': 'Rosenthal Preston R',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '13.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a220'),\n",
      " 'join_sample': [{'Nom': 'Rosenthal Preston R',\n",
      "                  'T_1': '13.00 / 16',\n",
      "                  'T_2': '13.00 / 18',\n",
      "                  'T_3': '11.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a22e')}]}\n",
      "{'Prenom_nom': 'Betty T',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a221'),\n",
      " 'join_sample': [{'Nom': 'Betty T',\n",
      "                  'T_1': '11.00 / 16',\n",
      "                  'T_2': '11.00 / 18',\n",
      "                  'T_3': '5.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a22f')}]}\n",
      "{'Prenom_nom': 'Mouloud B',\n",
      " 'Test_1': '13.00 / 16',\n",
      " 'Test_2': '17.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a222'),\n",
      " 'join_sample': [{'Nom': 'Mouloud B',\n",
      "                  'T_1': '13.00 / 16',\n",
      "                  'T_2': '17.00 / 18',\n",
      "                  'T_3': '4.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a230')}]}\n",
      "{'Prenom_nom': 'Joseph L',\n",
      " 'Test_1': '11.00 / 16',\n",
      " 'Test_2': '11.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a223'),\n",
      " 'join_sample': [{'Nom': 'Joseph L',\n",
      "                  'T_1': '11.00 / 16',\n",
      "                  'T_2': '11.00 / 18',\n",
      "                  'T_3': '8.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a231')}]}\n",
      "{'Prenom_nom': 'Nataliya P',\n",
      " 'Test_1': '10.00 / 16',\n",
      " 'Test_2': '9.00 / 18',\n",
      " '_id': ObjectId('67366f0bcddcbbed4846a224'),\n",
      " 'join_sample': [{'Nom': 'Nataliya P',\n",
      "                  'T_1': '10.00 / 16',\n",
      "                  'T_2': '9.00 / 18',\n",
      "                  'T_3': '9.00 / 18',\n",
      "                  '_id': ObjectId('67366f0bcddcbbed4846a232')}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "\n",
    "def csv_to_json_second_method(csv_file):\n",
    "    from json import dumps\n",
    "    csv_rows = []\n",
    "    with open(csv_file, encoding='latin1', newline='') as csv_file_handler:\n",
    "        csv_reader = csv.DictReader(csv_file_handler)\n",
    "        for row in csv_reader:\n",
    "            csv_rows.append(row)\n",
    "    return dumps(csv_rows)\n",
    "\n",
    "# Main program\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    mydb = client[\"mydatabase\"]\n",
    "    mycol_one = mydb[\"mycollection_one\"]\n",
    "    mycol_two = mydb[\"mycollection_two\"]\n",
    "\n",
    "    json_one = csv_to_json_second_method(\"../data/test_join.csv\")\n",
    "    json_two = csv_to_json_second_method(\"../data/test2_join.csv\")\n",
    "\n",
    "    d1_name = list(json.loads(json_one))\n",
    "    d2_name = list(json.loads(json_two))\n",
    "\n",
    "    mycol_one.insert_many(d1_name)\n",
    "    mycol_two.insert_many(d2_name)\n",
    "\n",
    "    # Print documents before aggregation\n",
    "    print(\"===== Collection 1 =====\")\n",
    "    for i in mycol_one.find({}):\n",
    "        pprint(i)\n",
    "\n",
    "    print(\"===== Collection 2 =====\")\n",
    "    for i in mycol_two.find({}):\n",
    "        pprint(i)\n",
    "\n",
    "    # compute the join with the lookup aggregation\n",
    "    agg_result = mycol_one.aggregate([\n",
    "        {\n",
    "            '$lookup': {\n",
    "                'from': 'mycollection_two',  # Correction ici\n",
    "                'localField': 'Prenom_nom',\n",
    "                'foreignField': 'Nom',\n",
    "                'as': 'join_sample'\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    print(\"===== Agrégation =====\")\n",
    "    for i in agg_result:\n",
    "        pprint(i)\n",
    "\n",
    "    # Clean up\n",
    "    mycol_one.drop()\n",
    "    mycol_two.drop()\n",
    "    client.drop_database('mydatabase')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp77MC4nAc9b",
    "outputId": "4c0b106b-e9da-463d-ecbc-8da7f1769c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type agrÃ©gation: <class 'pymongo.synchronous.command_cursor.CommandCursor'>\n",
      "=====  AgrÃ©gation  =====\n",
      "ObjectId('67366f2acddcbbed4846a23d')\n",
      "Nom : BETTY T\n",
      "Note 1 : 11.00 / 18\n",
      "Note 2 : 11.00 / 16\n",
      "Note 3 : 11.00 / 18\n",
      "Note 4 : 11.00 / 18\n",
      "Note 5 : 11.00 / 16\n",
      "------------------------\n",
      "ObjectId('67366f2acddcbbed4846a239')\n",
      "Nom : SARRA Z\n",
      "Note 1 : 6.00 / 18\n",
      "Note 2 : 11.00 / 16\n",
      "Note 3 : 6.00 / 18\n",
      "Note 4 : 6.00 / 18\n",
      "Note 5 : 11.00 / 16\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json_second_method(csv_file):\n",
    "\n",
    "    from json import dumps\n",
    "    #create a dictionary\n",
    "    data_dict = {}\n",
    "    csv_rows = []\n",
    "    #open a csv file handlerh\n",
    "    with open(csv_file, encoding = 'latin1', newline='') as csv_file_handler:\n",
    "        csv_reader = csv.DictReader(csv_file_handler)\n",
    "        field = csv_reader.fieldnames\n",
    "        for row in csv_reader:\n",
    "            #print([{field[i]:row[field[i]] for i in range(len(field))}])\n",
    "            csv_rows.extend([{field[i]:row[field[i]] for i in range(len(field))}])\n",
    "\n",
    "\n",
    "    z = dumps(csv_rows)\n",
    " \n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "# Main program\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    from pymongo import MongoClient\n",
    "\n",
    "    mydb = client[\"mydatabase\"]\n",
    "    mycol_one = mydb[\"mycollection_one\"]\n",
    "    mycol_two = mydb[\"mycollection_two\"]\n",
    "\n",
    "    json_one = csv_to_json_second_method(\"../data/test_join.csv\")\n",
    "    json_two = csv_to_json_second_method(\"../data/test2_join.csv\")\n",
    "\n",
    "\n",
    "    from json import loads\n",
    "    from json import dumps\n",
    "\n",
    "    # First, transform json objects to dictionaries\n",
    "\n",
    "    d1_name = list(loads(json_one))\n",
    "    #print(d1_name)\n",
    "    d2_name = list(loads(json_two))\n",
    "    #print(d2_name)\n",
    "\n",
    "    for row in d1_name:\n",
    "        #print(type(row),\"===\",row)\n",
    "        mydb.mycol_one.insert_one(row)\n",
    "    #mycol_one.insert_many(list(json_one))\n",
    "\n",
    "    for row in d2_name:\n",
    "        mydb.mycol_two.insert_one(row)\n",
    "    #mycol_two.insert_many(list(json_two))\n",
    "\n",
    "    # compute the join with the lookup aggregation\n",
    "    agg_result = mydb.mycol_one.aggregate([\n",
    "        { \"$match\": { \"$or\": [ { \"Prenom_nom\" : \"Betty T\" }, { \"Prenom_nom\" : \"Sarra Z\" }] } },\n",
    "        {\n",
    "            '$lookup': {\n",
    "                'from': 'mycol_two',\n",
    "                'localField': 'Prenom_nom',\n",
    "                'foreignField': 'Nom',\n",
    "                'as': 'join_sample'\n",
    "            }\n",
    "        },\n",
    "        { \"$unwind\": \"$join_sample\" },\n",
    "        #{ \"$group\": { \"_id\": \"$join_sample\", \"count\": { \"$sum\": 1 } } }\n",
    "        { \"$project\" : { \"name\":{\"$toUpper\":\"$Prenom_nom\"}, \"N2\":\"$Test_2\", \"N1\":\"$Test_1\", \"N3\":\"$join_sample.T_3\", \"N3\":\"$join_sample.T_2\",\"N1\":\"$join_sample.T_1\"}  },\n",
    "        { \"$sort\" : { \"name\" : 1 } }\n",
    "    ])\n",
    "\n",
    "    # print the 3 documents in the collection\n",
    "    from pprint import pprint\n",
    "\n",
    "    print(\"Type agrÃ©gation:\",type(agg_result))\n",
    "\n",
    "    print(\"=====  AgrÃ©gation  =====\")\n",
    "    for i in agg_result:\n",
    "        pprint(i[\"_id\"])\n",
    "        print('Nom :',i[\"name\"])\n",
    "        print('Note 1 :',i[\"N2\"])\n",
    "        print('Note 2 :',i[\"N1\"])\n",
    "        print('Note 3 :',i[\"N3\"])\n",
    "        print('Note 4 :',i[\"N2\"])\n",
    "        print('Note 5 :',i[\"N1\"])\n",
    "        print('------------------------')\n",
    "\n",
    "  \n",
    "    # On fait du mÃ©nage\n",
    "    mydb.mycol_one.drop()\n",
    "    mydb.mycol_two.drop()\n",
    "    client.drop_database('mydatabase')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
